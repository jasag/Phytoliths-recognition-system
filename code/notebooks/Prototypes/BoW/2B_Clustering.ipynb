{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crear vocabulario \n",
    "\n",
    "En un principio partiremos de las características de HoG para  crear nuestro vocabulario, aunque se podría hacer con cualquier otras.\n",
    "\n",
    "Importamos las características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path = '../../rsc/obj/'\n",
    "\n",
    "X_train_path = path + 'X_train.sav'\n",
    "\n",
    "train_features = pickle.load(open(X_train_path, 'rb'))\n",
    "\n",
    "# import pickle # Módulo para serializar\n",
    "# import numpy as np\n",
    "\n",
    "# path = '..//..//rsc//obj//BoW_features//'\n",
    "\n",
    "# for i in (15000,30000,45000,53688):\n",
    "#     daisy_features_path = path + 'BoW_features'+ str(i) +'.sav'\n",
    "#     if i == 15000:\n",
    "#         train_features = pickle.load(open(daisy_features_path, 'rb'))\n",
    "#     set_to_add = pickle.load(open(daisy_features_path, 'rb'))\n",
    "#     train_features = np.vstack((train_features,set_to_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  B. Construcción del vocabulario mediante un algoritmo de clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón por la que utilizamos un algoritmo de clustering es para la agrupación de dichas palabras en un determinado número de grupos. De manera que estos grupos de palabras resulten en patrones visuales que aporten mayor información al clasificador y, por lo tanto, nos permitan llevar a cabo una clasificación más eficiente.\n",
    "\n",
    "Vamos a proceder a entrenar dos variantes de algoritmos de clustering :\n",
    "- KMeans\n",
    "- MiniBatchKMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.cluster import MiniBatchKMeans as MiniKMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Se inicializa el algoritmo de Kmeans indicando el número de clusters\n",
    "mini_kmeans = MiniKMeans(500)\n",
    "#se construye el clusterr con todas las características del conjunto de entramiento\n",
    "mini_kmeans.fit(train_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializamos Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle # Módulo para serializar\n",
    "\n",
    "path = '../../rsc/obj/'\n",
    "\n",
    "mini_kmeans_path = path + 'mini_kmeans.sav'\n",
    "\n",
    "pickle.dump(mini_kmeans, open(mini_kmeans_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
