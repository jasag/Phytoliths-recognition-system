{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características de HoG\n",
    "\n",
    "En este notebook se creara un conjunto de imagenes con caras y no caras. Mediante las que obtendremos las características de HoG que nos servirán como conjunto de entrenamiento para nuestro clasificador.\n",
    "\n",
    "Además, estas características serán serializadas para que  podamos acceder a ellas las veces que deseemos evitando su procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Oriented Gradients (HoG)\n",
    "\n",
    "HoG es una técnica para la extracción de características, desarrollada en el contexto del procesamiento de imagenes, que involucra los siguientes pasos:\n",
    "\n",
    "1. Pre-normalizado de las imagenes. Aunque puede suponer una mayor dependencía de las características que varían segun la iluminación.\n",
    "2. Aplicar a la imagen dos filtros sensibles al brillo tanto horizontal como vertical. Lo cual nos aporta información sobre bordes, contornos y texturas.\n",
    "3. Subdividir la imagen en celdas de un tamaño concreto y calcular el histograma del gradiente para cada celda.\n",
    "4. Normalizar los histogramas, previamente calculados, mediante la comparación con sus vecinos. Eliminando así el efecto de la iluminación en la imagen.\n",
    "5. Construir un vector de caracteristicas unidimensional de la información de cada celda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crear un conjunto de entrenamiento de imagenes de caras que supongan positivos\n",
    "Scikit nos proporciona un conjunto de imagenes variadas de caras que nos permitiran obtener un conjunto de entrenamiento de positivos para nuestro objetivo. Más de 13000 caras para ser concretos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_lfw_people\n",
    "# faces = fetch_lfw_people()\n",
    "# positive_patches = faces.images\n",
    "# positive_patches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificación\n",
    "\n",
    "Vamos a proporcionar, de manera alternativa a la anterior, con nuestro propio conjunto de imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "positive_patches = list()\n",
    "\n",
    "path = \"..\\\\imgaug\\\\imgs\\\\\"\n",
    "for i in range(376):\n",
    "    for j in range(63):\n",
    "        image = io.imread(path+str(i)+str(j)+\".jpg\")\n",
    "        positive_patches.append(rgb2gray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crear un conjunto de entrenamiento de imagenes de no-caras que supongan falsos-positivos\n",
    "Una vez obtenido nuestro conjunto de positivos, necesitamos obtener un conjunto de imagenes que no tengan caras. Para ello, la técnica que se utiliza en el *notebook* en el que me estoy basando es obtener diversas imagenes de las cuales se obtienen subimagenes o miniaturas,*thumbnails* en ingles, con diversas escalas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import feature, color, data, transform\n",
    "\n",
    "imgs_to_use = ['camera', 'text', 'coins', 'moon',\n",
    "               'page', 'clock', 'immunohistochemistry',\n",
    "               'chelsea', 'coffee', 'hubble_deep_field']\n",
    "images = [color.rgb2gray(getattr(data, name)())\n",
    "          for name in imgs_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 62, 47)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "\n",
    "def extract_patches(img, N, scale=1.0, patch_size=positive_patches[0].shape):\n",
    "    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))\n",
    "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
    "                               max_patches=N, random_state=0)\n",
    "    patches = extractor.transform(img[np.newaxis])\n",
    "    if scale != 1:\n",
    "        patches = np.array([transform.resize(patch, patch_size)\n",
    "                            for patch in patches])\n",
    "    return patches\n",
    "\n",
    "# negative_patches = np.vstack([extract_patches(im, 1000, scale)\n",
    "#                               for im in images for scale in [0.5, 1.0, 2.0]])\n",
    "# negative_patches.shape\n",
    "\n",
    "# Alternativa\n",
    "negative_patches = np.vstack([extract_patches(im, 1000, scale, patch_size=(62,47))\n",
    "                              for im in images for scale in [0.5, 1.0, 2.0]])\n",
    "negative_patches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extraer las características de HoG del conjunto de entrenamiento\n",
    "Este tercer paso resulta de especial interes, puesto que vamos a obtener las características de HoG sobre las que previamente hemos hablado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 62, 47) (23688, 62, 47)\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "positive_patches = np.array(positive_patches)\n",
    "print(negative_patches.shape, positive_patches.shape)\n",
    "X_train = np.array([feature.hog(im)\n",
    "                    for im in chain(positive_patches,\n",
    "                                    negative_patches)])\n",
    "y_train = np.zeros(X_train.shape[0])\n",
    "y_train[:positive_patches.shape[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle # Módulo para serializar\n",
    "\n",
    "path = '..//rsc//obj//'\n",
    "\n",
    "X_train_path = path + 'X_train.sav'\n",
    "y_train_path = path + 'y_train.sav'\n",
    "\n",
    "pickle.dump(X_train, open(X_train_path, 'wb'))\n",
    "pickle.dump(y_train, open(y_train_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Serializamos el conjunto de entrenamiento\n",
    "Simplemente almacenamos los objetos *X_train* e *y_train* para, como explicabamos al principio, evitar el recalculo de estas características cada vez que deseemos utilizarlas."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
